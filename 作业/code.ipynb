{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67eb9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.optim.lr_scheduler import StepLR,ExponentialLR,CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29629a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model to get a higher performance\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()# batch*1*28*28（每次会送入batch个样本，输入通道数1（黑白图像），图像分辨率是28x28）\n",
    "        #in_channels=1,out_channels=8,kernel_size=3,stride=1\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, 1)# 输出数据大小变为28-3+1=26.所以batchx1x28x28 -> batchx8x26x26   \n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, 1)#第一个卷积层的输出通道数等于第二个卷积层的输入通道数。\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2304, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)#（激活函数ReLU不改变形状）\n",
    "        x = self.conv2(x)  \n",
    "        x = F.relu(x)#（激活函数ReLU不改变形状）\n",
    "        x = F.max_pool2d(x, 2)# batch*8x26x26  -> batch*8*13*13（2*2的池化层会减半，步长为2）此时输出数据大小变为13-3+2=12（卷积核大小为3），所以 batchx8x13x13 -> batchx16x12x12。\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs = []\n",
    "def train(args, model, device, train_loader, optimizer, epoch):# 定义每个epoch的训练细节\n",
    "    total = 0 # 总样本数量\n",
    "    running_loss = 0 # 记录当前的损失值\n",
    "    accuracy = 0 #记录每次epoch的accuracy\n",
    "    model.train() # 设置为trainning模式\n",
    "    plt.figure()\n",
    "    pic = None\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        if batch_idx in (1,2,3,4,5): # 图像拼接 针对前五个图像进行拼接\n",
    "            if batch_idx == 1:\n",
    "                pic = data[0,0,:,:] # 第一个样本， 第一个通到，整个宽高所有的图像\n",
    "            else:\n",
    "                pic = torch.cat((pic,data[0,0,:,:]),dim=1) # 按照高度进行拼接\n",
    "        data, target = data.to(device), target.to(device) # 部署标签和模型\n",
    "        optimizer.zero_grad()# 优化器梯度初始化为零\n",
    "        # forword + backward + update\n",
    "        output = model(data)# 把数据输入网络并得到输出，即进行前向传播\n",
    "        loss = F.cross_entropy(output, target) # 计算损失函数 \n",
    "        _, predicted = torch.max(output.data, dim=1)\n",
    "        if batch_idx == 1:\n",
    "            images = utils.make_grid(data,padding = 0)\n",
    "            image_show(images)\n",
    "            print('GroundTruth: ', ' '.join('%d' % target[j] for j in range(64)))\n",
    "            print('Predicted: ', ' '.join('%d' % predicted[j] for j in range(64)))\n",
    "        accuracy += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()# 反向传播梯度\n",
    "        \n",
    "        # Optimize the parameters according to the calculated gradients\n",
    "        optimizer.step()# 结束一次前传+反传之后，更新优化器参数\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "    train_accs.append(100 * accuracy/total)    \n",
    "    plt.imshow(pic.cpu(), cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d0819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(images):\n",
    "    images = images.numpy()\n",
    "    images = images.transpose((1, 2, 0))\n",
    "    print(images.shape)\n",
    "    plt.imshow(images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1fa5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = [] \n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss= 0\n",
    "    conf_matrix = torch.zeros(10, 10)\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #conf_matrix = confusion_matrix(output, target, conf_matrix)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            _, predicted = torch.max(output.data, dim=1)  # get the index of the max log-probability\n",
    "\n",
    "            if batch_idx == 1:\n",
    "                #images = utils.make_grid(data,padding = 0)\n",
    "                #image_show(images)\n",
    "                print('GroundTruth: ', ' '.join('%d' % target[j] for j in range(64)))\n",
    "                print('Predicted: ', ' '.join('%d' % predicted[j] for j in range(64)))\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()# 对预测正确的数据个数进行累加\n",
    "            # 不同类别的数量统计（区别于总体）\n",
    "            c = (predicted == target)\n",
    "            for i in range(10):\n",
    "                lable = target[i]\n",
    "                class_correct[lable] += c[i].sum().item()\n",
    "                class_total[lable] += 1\n",
    "            print(class_correct[i])\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)   # 因为把所有loss值进行过累加，所以最后要除以总得数据长度才得平均los\n",
    "                                            # 将变量值或属性值除以表达式值，并将浮点数结果赋给该变量或属性\n",
    "                                            # variableorproperty /= expression  \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    for i in range(10):\n",
    "        print('Accuracy of %0f : %2d %%' % \n",
    "                (i, 100* class_correct[i]\n",
    "                / class_total[i]))\n",
    "        \n",
    "    print(conf_matrix)\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #plot_confusion_matrix(conf_matrix, names)\n",
    "\n",
    "\n",
    "    test_accs.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc42dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    " \n",
    " \n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    " \n",
    "    fmt = '.2f' if normalize else '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0842431",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = (\"0\",\"1\",\"2\",\"3\",\"4\", \"5\",\"6\",\"7\",\"8\",\"9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0523c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(preds, labels, conf_matrix):\n",
    "    preds = torch.argmax(preds, 1)\n",
    "    for p,t in zip(preds,labels):\n",
    "        conf_matrix[p,t] += 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example') \n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',  # 训练的时候每次喂入的样本数量\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N', # 训练的时候每次喂入的样本数\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=14, metavar='N',   # 训练轮次\n",
    "                        help='number of epochs to train (default: 14)')  \n",
    "    parser.add_argument('--lr', type=float, default= 0.1, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status') # 每训练多少轮次以后记录一次状态\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    parser.add_argument('-f', type=str, default=\"读取额外的参数\")\n",
    "    args = parser.parse_args()  # 存储终端输入的参数\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed) # 设置torch的值\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\") # 运算使用GPU或者CPU\n",
    "\n",
    "    # batch_size is a crucial hyper-parameter\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        # Adjust num worker and pin memory according to your computer performance\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    # Normalize the input (black and white image)\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "    # Make train dataset split\n",
    "    dataset1 = datasets.MNIST(\"mnist-data\", train=True, download=True,\n",
    "                       transform=transform)\n",
    "    # Make test dataset split\n",
    "    dataset2 = datasets.MNIST(\"mnist-data\", train=False,\n",
    "                       transform=transform)\n",
    "\n",
    "    # Convert the dataset to dataloader, including train_kwargs and test_kwargs\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "    \n",
    "    # Put the model on the GPU or CPU\n",
    "    model = Net().to(device)\n",
    "     \n",
    "    '''\n",
    "   #这部分还没有跑通 但思路是这样\n",
    "    # 导入Pytorch中自带的resnet18网络模型\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # 将网络模型的各层的梯度更新置为False\n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    " \n",
    "    # 修改网络模型的最后一个全连接层\n",
    "    # 获取最后一个全连接层的输入通道数\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    # 修改最后一个全连接层的的输出数为10（0-9的数字）\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "    # 是否使用gpu\n",
    "    if use_gpu:\n",
    "        model_ft = model_ft.cuda()\n",
    " \n",
    "    # 定义网络模型的损失函数\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "    # 只训练最后一个层\n",
    "    # Create optimizer\n",
    "    optimizer = optim.Adadelta(model_ft.fc.parameters(), lr=args.lr/10)#The general approach is to make the initial learning rate 10 times smaller than that of Training from scratch.\n",
    "\n",
    "    '''\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr,)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9,0.99))\n",
    "    # 定义四个不同的优化器\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "    #optimizer = optim.SGD(model.parameters(),lr=args.lr, momentum=0.8)\n",
    "    #optimizer = optim.RMSprop(model.parameters(), lr=args.lr, alpha=0.9)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9,0.99))\n",
    "\n",
    "    # Create a schedule for the optimizer\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    #scheduler = ExponentialLR(optimizer, gamma=args.gamma)\n",
    "    scheduler= CosineAnnealingLR(optimizer,T_max=20,eta_min=0.05)\n",
    "    # Begin training and testing\n",
    "    epochs = []\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        epochs.append(epoch)\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "              \n",
    "    print(epochs) \n",
    "    print(test_accs)\n",
    "    print(train_accs)\n",
    "    \n",
    "   \n",
    "    plt.plot(epochs,train_accs,color='r',label='train_acc')        \n",
    "    plt.plot(epochs,test_accs,color='b',label='test_acc')  \n",
    "    plt.xlabel('epochs')    \n",
    "    plt.ylabel('accuracy')   \n",
    "    plt.title(\"change of train(test) accuracy\")      \n",
    "    plt.legend()     \n",
    "    plt.savefig('test.jpg')  \n",
    "    plt.show()               \n",
    "\n",
    "    # Save the model\n",
    "    if args.save_model == True:\n",
    "        torch.save(model.state_dict(), \"D://INT305//model//mnist_cnn.pt\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445d7360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
      "                             [--epochs N] [--lr LR] [--gamma M] [--no-cuda]\n",
      "                             [--dry-run] [--seed S] [--log-interval N]\n",
      "                             [--save-model] [-f F]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\29220\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3724acce090b65bbb2f71d996288ae25c9cad87c2.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\29220\\.conda\\envs\\torch\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cee9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9656b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5214615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ffafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c973212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc6738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
